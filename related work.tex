\documentclass[]{template}    
\begin{document}
\section{相关工作}
本章的工作和EBSN中的事件推荐和自然语言处理中的文本生成有着紧密联系。所以本章将首先介绍EBSN中关于事件推荐的相关工作，接着会介绍事件描述在事件推荐中的应用情况。最后由于本文研究了如何自动生成足够真实的事件描述，所以我们会介绍文本生成目前的研究现状。
\subsection{EBSN中事件推荐的相关工作}
在\cite{EBSN_event_reco}中，Yijun等人使用图理论研究了如何在EBSN中向事件的潜在参与人群推荐合适的事件。他们首先根据EBSN的网络结构构建了一个异构网络，然后在该网络上使用反向随机游走算法构建用户——事件推荐网络，并在此基础上构建推荐列表。在\cite{EBSN_conflict-aware_2016}中，Jieying等人率先将冲突事件的限制考虑进来，他们首先证明了在考虑冲突事件下获得事件安排的全局最优解是NP难的问题，随后他们提出了两种近似算法来获得较优解。在\cite{EBSN_feedback-aware_2017}中，Jieying等人将事件安排的反馈考虑进推荐算法中，通过被推荐人的RSVP结果，动态调整事件的推荐权重。

\subsection{事件描述在事件推荐中的应用}
事件描述作为事件的一个属性，在事件推荐中起到非常重要的作用。然而，到目前为止，几乎所有的论文中，事件描述都只被用来衡量事件间的相似度，以及事件与用户兴趣的契合度。比如在\cite{EBSN_who_will}中，事件描述被用来计算事件间的相似度，这样便可以根据用户参与事件的历史数据，来给他推荐相似的事件。而在\cite{gu_context_2016}中，Gu等人使用TF-IDF算法来处理事件描述，并用其计算事件间的相似度。通过以上论文，我们可以看出，目前关于事件描述的运用还非常局限。而在\cite{event_organization_101}中，Shuo等人提出用Vader对事件描述进行情感分析，并使用Jaccard相似度来衡量事件的新奇性。这也是据本文作者所知唯一一篇直接使用事件描述来对事件进行评价的论文。

\subsection{文本生成研究现状}
在自然语言处理中，目前运用最广泛的模型之一是Mikolov等人提出的RNNLM\cite{mikolov_rnnlm_2011}。而在文本生成领域，也有很多运用和改进RNNLM的例子。在\cite{}中，Xingxing等人运用一个RNN来生成中国诗。他们通过训练RNN学习单个字的表示，来使生成器学会生成在内容和平仄上都符合规范的古诗。在\cite{Character-AwareNeuralLanguageModels
}中，Kim等人对RNNLM做了改进，他们使用单个字符而非单个单词作为输入，在RNNLM前加入了卷积层和highway层，使得模型从字符的角度，而非单词的角度学会了如何表达自然语言。实验证明他们的改进模型能大大减少参数数量，并且在学习富词法语言中，表现优于传统的以词为最小单位的语言模型。

为了让RNNLM在生成文本时除了依赖当前状态，还依赖某个全局表达，以达成生成符合期望的文本的目的，人们提出了seq2seq模型，这样在生成文本的过程就成了编码-解码的过程。编码器首先将某段文本表示成一个隐向量，再通过解码器解码，以次达到对输出文本的控制效果。seq2seq模型被广泛运用于机器翻译和问答系统的设计中。在编码器的选择上，也有许多不同方案。在\cite{bowman_generating_2015}中，Bowman等人率先将变分自编码器引入文本生成中，他们利用变分自编码器通过采样得到编码的特性，确保了隐编码能够服从特定分布，从而保证了编码的连续性和局部相关性。而在\cite{noauthor_sequence_nodate}中，Muller等人也利用了变分自编码器编码空间连续的特性，通过一个对特定文本的编码进行梯度上升操作，来最大化某个目标函数，从而达到改进某段文本的目的。

为了使生成文本表现的更像真实文本，生成对抗网络也被引入到文本生成领域中。在\cite{yu_seqgan:_2016}中，yu等人设计了SeqGAN，一个使用RNNLM作为生成模型，以及带卷积层的神经网络作为判别模型的生成对抗网络，来训练生成模型生成和真实文本接近的文本序列。而在\cite{lin_adversarial_2017}中，Lin等人也采用了类似的结构，通过训练生成模型生成评分胜过真实训练数据的文本，来使其可以生成足够真实的文本序列。

\subsection{本章小节}
本章首先介绍了EBSN中事件推荐系统的研究现状，然后介绍了目前事件描述在事件推荐中的有限应用，最后介绍了目前文本生成的研究现状。
\end{document}